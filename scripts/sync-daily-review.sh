#!/bin/bash
# sync-daily-review.sh - Sync daily review to Own It backend

set -e

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Configuration
CONFIG_DIR="$HOME/.claude-daily-commands"
CONFIG_FILE="$CONFIG_DIR/config.json"

# Parse arguments
NO_SYNC=false
TIME_RANGE="today"

for arg in "$@"; do
  case "$arg" in
    --no-sync) NO_SYNC=true ;;
    yesterday|week) TIME_RANGE="$arg" ;;
  esac
done

# Check if in git repository
if ! git rev-parse --is-inside-work-tree &>/dev/null; then
  echo -e "${RED}âŒ Not a git repository${NC}"
  echo "ğŸ’¡ Run this command in a git repository"
  exit 1
fi

# Determine time range
case "$TIME_RANGE" in
  yesterday)
    SINCE="yesterday 00:00"
    UNTIL="yesterday 23:59"
    if [[ "$OSTYPE" == "darwin"* ]]; then
      DATE=$(date -v-1d +%Y-%m-%d)
    else
      DATE=$(date -d "yesterday" +%Y-%m-%d)
    fi
    ;;
  week)
    SINCE="7 days ago"
    UNTIL="now"
    DATE=$(date +%Y-%m-%d)
    ;;
  *)
    SINCE="today 00:00"
    UNTIL="now"
    DATE=$(date +%Y-%m-%d)
    ;;
esac

# Collect git data
GIT_LOG=$(git log --since="$SINCE" --until="$UNTIL" \
  --pretty=format:'COMMIT:%H|%ai|%s|%an' \
  --numstat \
  --no-merges 2>/dev/null || true)

if [ -z "$GIT_LOG" ]; then
  echo "ğŸ“­ No commits found for $DATE"
  exit 0
fi

# Get repository info
REPO_PATH=$(git rev-parse --show-toplevel)
REPO_REMOTE=$(git config --get remote.origin.url 2>/dev/null || echo "")

# Parse git data and create JSON using Python
JSON_DATA=$(python3 << PYTHON_EOF
import sys
import json
from collections import defaultdict

git_log = """$GIT_LOG"""
repo_path = """$REPO_PATH"""
repo_remote = """$REPO_REMOTE"""
review_date = """$DATE"""

commits = []
stats = {"commits": 0, "files": set(), "additions": 0, "deletions": 0}
file_changes = defaultdict(int)
current_commit = None

for line in git_log.strip().split('\n'):
    if line.startswith('COMMIT:'):
        if current_commit:
            commits.append(current_commit)

        # Parse: COMMIT:sha|datetime|message|author
        parts = line[7:].split('|', 3)
        if len(parts) >= 4:
            current_commit = {
                "sha": parts[0],
                "time": parts[1],
                "message": parts[2],
                "author": parts[3],
                "files": [],
                "additions": 0,
                "deletions": 0
            }
            stats["commits"] += 1
    elif '\t' in line and current_commit:
        # Parse numstat: additions\tdeletions\tfilename
        parts = line.split('\t')
        if len(parts) == 3:
            adds_str, dels_str, filename = parts
            adds = int(adds_str) if adds_str.isdigit() else 0
            dels = int(dels_str) if dels_str.isdigit() else 0

            current_commit["files"].append(filename)
            current_commit["additions"] += adds
            current_commit["deletions"] += dels

            stats["files"].add(filename)
            stats["additions"] += adds
            stats["deletions"] += dels

            file_changes[filename] += 1

# Add last commit
if current_commit:
    commits.append(current_commit)

# Analyze main work areas
main_areas = []
if file_changes:
    dir_changes = defaultdict(int)
    for file, count in file_changes.items():
        dir_name = file.split('/')[0] if '/' in file else 'root'
        dir_changes[dir_name] += count

    # Top 3 directories
    main_areas = sorted(dir_changes.items(), key=lambda x: x[1], reverse=True)[:3]
    main_areas = [area[0] for area in main_areas]

# Build JSON output
output = {
    "date": review_date,
    "stats": {
        "commits": stats["commits"],
        "files": len(stats["files"]),
        "additions": stats["additions"],
        "deletions": stats["deletions"]
    },
    "commits": commits,
    "analysis": {
        "mainAreas": main_areas,
        "fileChanges": dict(file_changes)
    }
}

# Add repository info if available
if repo_path and repo_remote:
    output["repository"] = {
        "path": repo_path,
        "remote": repo_remote
    }

print(json.dumps(output))
PYTHON_EOF
)

# Extract stats for display
COMMIT_COUNT=$(echo "$JSON_DATA" | python3 -c "import sys, json; print(json.load(sys.stdin)['stats']['commits'])")
FILE_COUNT=$(echo "$JSON_DATA" | python3 -c "import sys, json; print(json.load(sys.stdin)['stats']['files'])")
ADDITIONS=$(echo "$JSON_DATA" | python3 -c "import sys, json; print(json.load(sys.stdin)['stats']['additions'])")
DELETIONS=$(echo "$JSON_DATA" | python3 -c "import sys, json; print(json.load(sys.stdin)['stats']['deletions'])")
MAIN_AREAS=$(echo "$JSON_DATA" | python3 -c "import sys, json; areas = json.load(sys.stdin)['analysis']['mainAreas']; print(', '.join(areas[:2]) if areas else 'N/A')")

# Print local summary header
echo ""
echo "# ğŸ“… Daily Review - $DATE"
echo ""
echo "**${COMMIT_COUNT}ê°œ ì»¤ë°‹ | ${FILE_COUNT}ê°œ íŒŒì¼ | +${ADDITIONS}ì¤„ -${DELETIONS}ì¤„**"
echo ""

# ============================================
# AI Report Generation (Claude API)
# ============================================
AI_REPORT=""
CLAUDE_API_KEY=""

if [ -f "$CONFIG_FILE" ] && command -v jq &>/dev/null; then
  CLAUDE_API_KEY=$(jq -r '.claude_api_key // ""' "$CONFIG_FILE" 2>/dev/null || echo "")
fi

if [ -n "$CLAUDE_API_KEY" ]; then
  echo -e "${CYAN}ğŸ¤– AI ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...${NC}"

  # Create prompt for Claude
  PROMPT="ë‹¹ì‹ ì€ ê¸°ìˆ  ê°œë°œ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ Git ì»¤ë°‹ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ê°„ê²°í•˜ê³  í†µì°°ë ¥ ìˆëŠ” ì¼ì¼ ë¦¬ë·° ë¦¬í¬íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

Git ì»¤ë°‹ ë°ì´í„°:
- ë‚ ì§œ: $DATE
- ì»¤ë°‹ ìˆ˜: $COMMIT_COUNT
- ë³€ê²½ëœ íŒŒì¼: $FILE_COUNTê°œ
- ë¼ì¸ ë³€ê²½: +$ADDITIONS -$DELETIONS
- ì£¼ìš” ì‘ì—… ì˜ì—­: $MAIN_AREAS

ìƒì„¸ ì»¤ë°‹ ë‚´ì—­:
$GIT_LOG

ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨í•´ì£¼ì„¸ìš”:
1. ìš”ì•½ (2-3ë¬¸ì¥): ì „ë°˜ì ì¸ ê°œë°œ ë°©í–¥ê³¼ ëª©í‘œ
2. ì£¼ìš” ì„±ê³¼: ì˜¤ëŠ˜ ì™„ë£Œí•œ í•µì‹¬ ì‘ì—…ë“¤
3. ê¸°ìˆ ì  í•˜ì´ë¼ì´íŠ¸: ì£¼ëª©í•  ë§Œí•œ íŒ¨í„´, ë¦¬íŒ©í† ë§, ê°œì„ ì‚¬í•­
4. ê¶Œì¥ì‚¬í•­: ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìœ„í•œ ì œì•ˆ

ë¦¬í¬íŠ¸ëŠ” ê°„ê²°í•˜ê²Œ (300ë‹¨ì–´ ì´í•˜) ì‘ì„±í•˜ë˜ ì‹¤í–‰ ê°€ëŠ¥í•œ ë‚´ìš©ìœ¼ë¡œ êµ¬ì„±í•´ì£¼ì„¸ìš”.
ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ê³ , ì œëª©ì€ '# ğŸ“Š ì¼ì¼ ê°œë°œ ë¦¬ë·°'ë¡œ ì‹œì‘í•´ì£¼ì„¸ìš”."

  # Call Claude API
  CLAUDE_RESPONSE=$(curl -s https://api.anthropic.com/v1/messages \
    -H "content-type: application/json" \
    -H "x-api-key: $CLAUDE_API_KEY" \
    -H "anthropic-version: 2023-06-01" \
    -d "{
      \"model\": \"claude-haiku-4-5-20251001\",
      \"max_tokens\": 1024,
      \"messages\": [{
        \"role\": \"user\",
        \"content\": $(echo "$PROMPT" | python3 -c "import sys, json; print(json.dumps(sys.stdin.read()))")
      }]
    }" 2>/dev/null)

  # Extract AI report and token usage from response
  TOKENS_INPUT=0
  TOKENS_OUTPUT=0
  TOKENS_CACHE_CREATION=0
  TOKENS_CACHE_READ=0

  if [ -n "$CLAUDE_RESPONSE" ]; then
    # Parse response and extract both AI report and token usage
    PARSED_RESPONSE=$(echo "$CLAUDE_RESPONSE" | python3 -c "
import sys, json
try:
    data = json.load(sys.stdin)
    result = {'report': '', 'tokens_input': 0, 'tokens_output': 0, 'tokens_cache_creation': 0, 'tokens_cache_read': 0}

    # Extract AI report text
    if 'content' in data and len(data['content']) > 0:
        result['report'] = data['content'][0]['text']

    # Extract token usage from 'usage' field
    if 'usage' in data:
        usage = data['usage']
        result['tokens_input'] = usage.get('input_tokens', 0)
        result['tokens_output'] = usage.get('output_tokens', 0)

        # Cache tokens (if available)
        if 'cache_creation_input_tokens' in usage:
            result['tokens_cache_creation'] = usage['cache_creation_input_tokens']
        if 'cache_read_input_tokens' in usage:
            result['tokens_cache_read'] = usage['cache_read_input_tokens']

    print(json.dumps(result))
except Exception as e:
    print(json.dumps({'report': '', 'tokens_input': 0, 'tokens_output': 0, 'tokens_cache_creation': 0, 'tokens_cache_read': 0}))
" 2>/dev/null || echo '{"report":"","tokens_input":0,"tokens_output":0,"tokens_cache_creation":0,"tokens_cache_read":0}')

    # Extract values from parsed response
    AI_REPORT=$(echo "$PARSED_RESPONSE" | python3 -c "import sys, json; print(json.load(sys.stdin).get('report', ''))" 2>/dev/null || echo "")
    TOKENS_INPUT=$(echo "$PARSED_RESPONSE" | python3 -c "import sys, json; print(json.load(sys.stdin).get('tokens_input', 0))" 2>/dev/null || echo "0")
    TOKENS_OUTPUT=$(echo "$PARSED_RESPONSE" | python3 -c "import sys, json; print(json.load(sys.stdin).get('tokens_output', 0))" 2>/dev/null || echo "0")
    TOKENS_CACHE_CREATION=$(echo "$PARSED_RESPONSE" | python3 -c "import sys, json; print(json.load(sys.stdin).get('tokens_cache_creation', 0))" 2>/dev/null || echo "0")
    TOKENS_CACHE_READ=$(echo "$PARSED_RESPONSE" | python3 -c "import sys, json; print(json.load(sys.stdin).get('tokens_cache_read', 0))" 2>/dev/null || echo "0")

    if [ -n "$AI_REPORT" ]; then
      echo -e "${GREEN}âœ… AI ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ${NC}"
      echo -e "${CYAN}ğŸ“Š í† í° ì‚¬ìš©: Input=$TOKENS_INPUT, Output=$TOKENS_OUTPUT${NC}"
      if [ "$TOKENS_CACHE_CREATION" -gt 0 ] || [ "$TOKENS_CACHE_READ" -gt 0 ]; then
        echo -e "${CYAN}   Cache: Creation=$TOKENS_CACHE_CREATION, Read=$TOKENS_CACHE_READ${NC}"
      fi
      echo ""
    else
      echo -e "${YELLOW}âš ï¸  AI ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨ (ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜)${NC}"
      echo ""
    fi
  else
    echo -e "${YELLOW}âš ï¸  AI ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨ (API í˜¸ì¶œ ì˜¤ë¥˜)${NC}"
    echo ""
  fi
else
  echo -e "${YELLOW}ğŸ’¡ AI ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ë ¤ë©´ Claude API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”${NC}"
  echo "   ì„¤ì • ë°©ë²•: ~/.claude-daily-commands/config.jsonì— 'claude_api_key' ì¶”ê°€"
  echo ""
fi

# Add AI report and token usage to JSON data
echo "[DEBUG] Before adding AI report - AI_REPORT length: ${#AI_REPORT}" >&2
if [ -n "$AI_REPORT" ]; then
  echo "[DEBUG] AI_REPORT is NOT empty, adding to JSON..." >&2
  JSON_DATA=$(echo "$JSON_DATA" | AI_REPORT="$AI_REPORT" python3 -c "
import sys, json, os
data = json.load(sys.stdin)
ai_report = os.environ.get('AI_REPORT', '')
data['aiReport'] = ai_report
print(f'[DEBUG-PYTHON] ai_report length: {len(ai_report)}', file=sys.stderr)

# Add token usage information
data['tokenUsage'] = {
    'input': int($TOKENS_INPUT),
    'output': int($TOKENS_OUTPUT),
    'cacheCreation': int($TOKENS_CACHE_CREATION),
    'cacheRead': int($TOKENS_CACHE_READ),
    'total': int($TOKENS_INPUT) + int($TOKENS_OUTPUT) + int($TOKENS_CACHE_CREATION) + int($TOKENS_CACHE_READ)
}

# Calculate cost (Claude 3.5 Sonnet pricing)
# Input: \$3 per MTok, Output: \$15 per MTok
# Cache creation: \$3.75 per MTok, Cache read: \$0.30 per MTok
input_cost = (int($TOKENS_INPUT) / 1_000_000) * 3.0
output_cost = (int($TOKENS_OUTPUT) / 1_000_000) * 15.0
cache_creation_cost = (int($TOKENS_CACHE_CREATION) / 1_000_000) * 3.75
cache_read_cost = (int($TOKENS_CACHE_READ) / 1_000_000) * 0.30
total_cost = input_cost + output_cost + cache_creation_cost + cache_read_cost

data['cost'] = {
    'usd': round(total_cost, 4)
}

print(json.dumps(data))
")
else
  echo "[DEBUG] AI_REPORT is EMPTY, skipping aiReport field" >&2
fi

# ============================================
# Claude Code Token Collection (from session JSONL files)
# ============================================
echo -e "${CYAN}ğŸ” Claude Code í† í° ì‚¬ìš©ëŸ‰ ìˆ˜ì§‘ ì¤‘...${NC}"

CLAUDE_TOKENS=$(DATE="$DATE" REPO_PATH="$REPO_PATH" python3 << 'PYTHON_TOKENS'
import sys
import json
import os
from pathlib import Path
from datetime import datetime
from glob import glob

# Get target date and repository path
target_date = os.environ.get('DATE', datetime.now().strftime('%Y-%m-%d'))
repo_path = os.environ.get('REPO_PATH', '').strip()

# Normalize repository path for comparison
if repo_path:
    repo_path = os.path.abspath(repo_path)

# Initialize token counters
tokens = {
    'input': 0,
    'output': 0,
    'cache_creation': 0,
    'cache_read': 0,
    'total': 0
}

# Define Claude data directories to search
claude_dirs = []
config_dir = os.environ.get('CLAUDE_CONFIG_DIR', '').strip()

if config_dir:
    # Use environment variable paths
    for path in config_dir.split(','):
        path = path.strip()
        if path and os.path.isdir(path):
            claude_dirs.append(path)
else:
    # Default paths
    home = str(Path.home())
    xdg_config = os.environ.get('XDG_CONFIG_HOME', os.path.join(home, '.config'))
    default_paths = [
        os.path.join(xdg_config, 'claude'),
        os.path.join(home, '.claude')
    ]
    claude_dirs = [p for p in default_paths if os.path.isdir(p)]

# Search for JSONL files in all Claude directories
for claude_dir in claude_dirs:
    projects_dir = os.path.join(claude_dir, 'projects')
    if not os.path.isdir(projects_dir):
        continue

    # Find all JSONL session files
    pattern = os.path.join(projects_dir, '**', '*.jsonl')
    jsonl_files = glob(pattern, recursive=True)

    for jsonl_path in jsonl_files:
        try:
            with open(jsonl_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue

                    try:
                        entry = json.loads(line)

                        # Check if entry has required fields
                        if 'timestamp' not in entry or 'message' not in entry:
                            continue

                        # Filter by current repository path (cwd field)
                        if repo_path:
                            entry_cwd = entry.get('cwd', '').strip()
                            if entry_cwd:
                                entry_cwd = os.path.abspath(entry_cwd)
                                # Check if entry is from current repository
                                if not entry_cwd.startswith(repo_path):
                                    continue

                        # Parse timestamp and check if it matches target date
                        timestamp = entry['timestamp']
                        entry_date = timestamp.split('T')[0]  # Extract YYYY-MM-DD

                        if entry_date != target_date:
                            continue

                        # Extract usage from message
                        message = entry.get('message', {})
                        usage = message.get('usage', {})

                        if not usage:
                            continue

                        # Accumulate tokens
                        tokens['input'] += usage.get('input_tokens', 0)
                        tokens['output'] += usage.get('output_tokens', 0)
                        tokens['cache_creation'] += usage.get('cache_creation_input_tokens', 0)
                        tokens['cache_read'] += usage.get('cache_read_input_tokens', 0)

                    except json.JSONDecodeError:
                        continue
        except Exception:
            continue

# Calculate total
tokens['total'] = tokens['input'] + tokens['output'] + tokens['cache_creation'] + tokens['cache_read']

# Calculate cost (Claude 3.5 Sonnet pricing)
input_cost = (tokens['input'] / 1_000_000) * 3.0
output_cost = (tokens['output'] / 1_000_000) * 15.0
cache_creation_cost = (tokens['cache_creation'] / 1_000_000) * 3.75
cache_read_cost = (tokens['cache_read'] / 1_000_000) * 0.30
total_cost = input_cost + output_cost + cache_creation_cost + cache_read_cost

result = {
    'tokens': tokens,
    'cost_usd': round(total_cost, 4)
}

print(json.dumps(result))
PYTHON_TOKENS
)

# Extract Claude Code token data
CC_TOKENS_INPUT=$(echo "$CLAUDE_TOKENS" | python3 -c "import sys, json; print(json.load(sys.stdin)['tokens']['input'])" 2>/dev/null || echo "0")
CC_TOKENS_OUTPUT=$(echo "$CLAUDE_TOKENS" | python3 -c "import sys, json; print(json.load(sys.stdin)['tokens']['output'])" 2>/dev/null || echo "0")
CC_TOKENS_CACHE_CREATION=$(echo "$CLAUDE_TOKENS" | python3 -c "import sys, json; print(json.load(sys.stdin)['tokens']['cache_creation'])" 2>/dev/null || echo "0")
CC_TOKENS_CACHE_READ=$(echo "$CLAUDE_TOKENS" | python3 -c "import sys, json; print(json.load(sys.stdin)['tokens']['cache_read'])" 2>/dev/null || echo "0")
CC_TOKENS_TOTAL=$(echo "$CLAUDE_TOKENS" | python3 -c "import sys, json; print(json.load(sys.stdin)['tokens']['total'])" 2>/dev/null || echo "0")
CC_COST_USD=$(echo "$CLAUDE_TOKENS" | python3 -c "import sys, json; print(json.load(sys.stdin)['cost_usd'])" 2>/dev/null || echo "0.0000")

if [ "$CC_TOKENS_TOTAL" -gt "0" ]; then
  echo -e "${GREEN}âœ… Claude Code í† í°: ${CC_TOKENS_TOTAL} (ë¹„ìš©: \$${CC_COST_USD})${NC}"
  echo "   Input: ${CC_TOKENS_INPUT} | Output: ${CC_TOKENS_OUTPUT}"
  echo "   Cache Creation: ${CC_TOKENS_CACHE_CREATION} | Cache Read: ${CC_TOKENS_CACHE_READ}"
else
  echo -e "${YELLOW}âš ï¸  Claude Code í† í° ì‚¬ìš© ë‚´ì—­ ì—†ìŒ${NC}"
fi
echo ""

# Add Claude Code usage to JSON data
JSON_DATA=$(echo "$JSON_DATA" | python3 -c "
import sys, json
data = json.load(sys.stdin)

# Add Claude Code token usage
data['claudeCodeUsage'] = {
    'input': int($CC_TOKENS_INPUT),
    'output': int($CC_TOKENS_OUTPUT),
    'cacheCreation': int($CC_TOKENS_CACHE_CREATION),
    'cacheRead': int($CC_TOKENS_CACHE_READ),
    'total': int($CC_TOKENS_TOTAL),
    'costUsd': float($CC_COST_USD)
}

print(json.dumps(data))
")

# Determine sync mode (authenticated vs anonymous)
MODE="anonymous"
API_KEY=""
API_URL="http://localhost:4000"

if [ -f "$CONFIG_FILE" ] && command -v jq &>/dev/null; then
  API_KEY=$(jq -r '.ownit_api_key // ""' "$CONFIG_FILE" 2>/dev/null || echo "")
  CUSTOM_API_URL=$(jq -r '.ownit_api_url // ""' "$CONFIG_FILE" 2>/dev/null || echo "")

  if [ -n "$CUSTOM_API_URL" ]; then
    API_URL="$CUSTOM_API_URL"
  fi

  if [ -n "$API_KEY" ]; then
    MODE="authenticated"
  fi
fi

# Sync to backend (if not disabled)
SYNC_SUCCESS=false
REVIEW_URL=""

if [ "$NO_SYNC" = false ]; then
  if [ "$MODE" = "authenticated" ]; then
    # ============================================
    # Authenticated Mode (ê¸°ì¡´ ë¡œì§)
    # ============================================
    echo -e "${CYAN}ğŸ”„ Own Itì— ë™ê¸°í™” ì¤‘... (ì¸ì¦ ëª¨ë“œ)${NC}"

    ENDPOINT="$API_URL/api/daily-reviews/sync"

    RESPONSE=$(curl -s -w "\n%{http_code}" -X POST "$ENDPOINT" \
      -H "Authorization: Bearer $API_KEY" \
      -H "Content-Type: application/json" \
      -d "$JSON_DATA")

    HTTP_CODE=$(echo "$RESPONSE" | tail -n1)
    BODY=$(echo "$RESPONSE" | sed '$d')

    if [ "$HTTP_CODE" = "200" ] || [ "$HTTP_CODE" = "201" ]; then
      if echo "$BODY" | python3 -c "import sys, json; exit(0 if json.load(sys.stdin).get('success') else 1)" 2>/dev/null; then
        REVIEW_ID=$(echo "$BODY" | python3 -c "import sys, json; print(json.load(sys.stdin)['data']['id'])" 2>/dev/null || echo "")
        echo -e "${GREEN}âœ… Own It ë™ê¸°í™” ì™„ë£Œ!${NC}"
        if [ -n "$REVIEW_ID" ]; then
          WEB_URL=$(echo "$API_URL" | sed 's/:4000/:3000/')
          REVIEW_URL="${WEB_URL}/daily/${REVIEW_ID}"
          echo "ğŸ“Š ë¦¬ë·° í™•ì¸: ${REVIEW_URL}"
        fi
        echo ""
        SYNC_SUCCESS=true
      else
        ERROR_MSG=$(echo "$BODY" | python3 -c "import sys, json; print(json.load(sys.stdin).get('message', 'Unknown error'))" 2>/dev/null || echo "Unknown error")
        echo -e "${RED}âŒ ë™ê¸°í™” ì‹¤íŒ¨: $ERROR_MSG${NC}"
        echo ""
      fi
    else
      echo -e "${RED}âŒ ë™ê¸°í™” ì‹¤íŒ¨ (HTTP $HTTP_CODE)${NC}"
      echo ""
    fi

  else
    # ============================================
    # Anonymous Mode (ìƒˆë¡œìš´ ë¡œì§)
    # ============================================
    echo -e "${CYAN}ğŸ”„ Own Itì— ì—…ë¡œë“œ ì¤‘... (ìµëª… ëª¨ë“œ)${NC}"

    ENDPOINT="$API_URL/api/anonymous-reviews"

    RESPONSE=$(curl -s -w "\n%{http_code}" -X POST "$ENDPOINT" \
      -H "Content-Type: application/json" \
      -d "$JSON_DATA")

    HTTP_CODE=$(echo "$RESPONSE" | tail -n1)
    BODY=$(echo "$RESPONSE" | sed '$d')

    if [ "$HTTP_CODE" = "200" ] || [ "$HTTP_CODE" = "201" ]; then
      if echo "$BODY" | python3 -c "import sys, json; exit(0 if json.load(sys.stdin).get('success') else 1)" 2>/dev/null; then
        REVIEW_URL=$(echo "$BODY" | python3 -c "import sys, json; print(json.load(sys.stdin)['data']['url'])" 2>/dev/null || echo "")
        EXPIRES_AT=$(echo "$BODY" | python3 -c "import sys, json; print(json.load(sys.stdin)['data']['expiresAt'])" 2>/dev/null || echo "")

        echo -e "${GREEN}âœ… ìµëª… ë¦¬ë·° ìƒì„± ì™„ë£Œ!${NC}"
        echo ""
        echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
        echo -e "${YELLOW}ğŸ’¡ ì›¹ì—ì„œ ì˜ˆì˜ê²Œ ë³´ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?${NC}"
        echo ""
        echo "ë¸Œë¼ìš°ì €ì—ì„œ íƒ€ì„ë¼ì¸ê³¼ í†µê³„ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
        echo -e "${BLUE}${REVIEW_URL}${NC}"
        echo ""
        echo -e "${YELLOW}âš ï¸  ì£¼ì˜: ìµëª… ë¦¬ë·°ëŠ” 24ì‹œê°„ í›„ ìë™ ì‚­ì œë©ë‹ˆë‹¤${NC}"
        if [ -n "$EXPIRES_AT" ]; then
          echo "   ë§Œë£Œ ì‹œê°„: $EXPIRES_AT"
        fi
        echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
        echo ""

        # ë¸Œë¼ìš°ì € ì˜¤í”ˆ ì—¬ë¶€ ë¬¼ì–´ë³´ê¸°
        read -p "ì§€ê¸ˆ ë¸Œë¼ìš°ì €ì—ì„œ ë³´ì‹œê² ìŠµë‹ˆê¹Œ? (Y/n) " -n 1 -r
        echo ""

        if [[ $REPLY =~ ^[Yy]$ ]] || [[ -z $REPLY ]]; then
          echo -e "${CYAN}ğŸŒ ë¸Œë¼ìš°ì € ì—´ê¸°...${NC}"

          # OSë³„ ë¸Œë¼ìš°ì € ì˜¤í”ˆ
          if [[ "$OSTYPE" == "darwin"* ]]; then
            # macOS
            open "$REVIEW_URL"
          elif [[ "$OSTYPE" == "linux-gnu"* ]]; then
            # Linux
            if command -v xdg-open &>/dev/null; then
              xdg-open "$REVIEW_URL"
            else
              echo -e "${YELLOW}âš ï¸  xdg-openì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì§ì ‘ ë°©ë¬¸í•˜ì„¸ìš”:${NC}"
              echo "$REVIEW_URL"
            fi
          elif [[ "$OSTYPE" == "msys" ]] || [[ "$OSTYPE" == "cygwin" ]]; then
            # Windows Git Bash
            start "$REVIEW_URL"
          else
            echo -e "${YELLOW}âš ï¸  OSë¥¼ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì§ì ‘ ë°©ë¬¸í•˜ì„¸ìš”:${NC}"
            echo "$REVIEW_URL"
          fi

          echo ""
          echo -e "${GREEN}âœ… ë¸Œë¼ìš°ì €ê°€ ì—´ë ¸ìŠµë‹ˆë‹¤!${NC}"
          echo ""
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo -e "${CYAN}ğŸ’¼ ê³„ì† ì´ë ‡ê²Œ ë³´ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?${NC}"
          echo ""
          echo "GitHubë¡œ ë¡œê·¸ì¸í•˜ë©´:"
          echo "  âœ“ ë¬´ì œí•œ ì €ì¥"
          echo "  âœ“ ì–¸ì œë“  í™•ì¸ ê°€ëŠ¥"
          echo "  âœ“ ìë™ í¬íŠ¸í´ë¦¬ì˜¤ ìƒì„±"
          echo ""
          echo -e "íšŒì›ê°€ì…: ${BLUE}${API_URL}${NC}"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo ""
        fi

        SYNC_SUCCESS=true
      else
        ERROR_MSG=$(echo "$BODY" | python3 -c "import sys, json; print(json.load(sys.stdin).get('error', 'Unknown error'))" 2>/dev/null || echo "Unknown error")
        echo -e "${RED}âŒ ì—…ë¡œë“œ ì‹¤íŒ¨: $ERROR_MSG${NC}"
        echo ""
      fi
    else
      echo -e "${RED}âŒ ì—…ë¡œë“œ ì‹¤íŒ¨ (HTTP $HTTP_CODE)${NC}"
      echo ""
    fi
  fi
fi

# Print commit timeline
echo "## Timeline"
echo ""
echo "$GIT_LOG" | grep '^COMMIT:' | while IFS='|' read -r commit_line; do
  SHA=$(echo "$commit_line" | cut -d'|' -f1 | sed 's/COMMIT://')
  DATETIME=$(echo "$commit_line" | cut -d'|' -f2)
  TIME=$(echo "$DATETIME" | awk '{print $2}' | cut -d':' -f1,2)
  MSG=$(echo "$commit_line" | cut -d'|' -f3)

  # Get main directory for this commit
  MAIN_DIR=$(git show --stat --format="" "$SHA" 2>/dev/null | head -5 | awk '{print $1}' | xargs -I{} dirname {} 2>/dev/null | sort | uniq -c | sort -rn | head -1 | awk '{print $2}' || echo ".")

  echo "[$TIME] $MSG ($MAIN_DIR)"
done

echo ""
echo "ğŸ’¡ ì£¼ìš” ì‘ì—…: $MAIN_AREAS"
echo ""
